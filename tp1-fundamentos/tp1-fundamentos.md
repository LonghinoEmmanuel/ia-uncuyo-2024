# Ejercicio 1
## Cimientos Filosóficos
A la hora de tratar la inteligencia artificial, existen temas a tratar más allá de las secciones prácticas e ingeniería, pues existe una fuerte componente filosófica que realiza la pregunta *¿Cómo piensa la mente? ¿Podría una máquina imitarlo, y si es así entonces la máquina también pensaría? ¿Qué significa eso para la vida humana y nuestra ética moral?*

Para tratar el tema se realizó dos hipótesis distinguiendo **IA débil** como aquella que imita inteligencia y **IA fuerte** como aquella que posee inteligencia y piensa realmente. Para la mayor parte de desarrolladores estas cuestiones filosóficas son irrelevantes pues la IA es tratada como una herramienta y nada más, mientras funcione alcanza. Pero igualmente todos deben tener en cuenta la parte ética de su propio trabajo.
### IA Débil
Para determinar si la IA débil es posible se debe establecer una definición para inteligencia, pues esta es la base de la IA, si es capaz de imitar la o no. Para ingenieros y desarrolladores, inteligencia indica si es capaz de realizar una tarea buscando una forma óptima, pero esta definición es meramente práctica y los filósofos trabajan en la teoría no en la práctica. 

Para ellos la cuestión está en la comparación de dos arquitecturas, la humana y la máquina. Entonces la pregunta en realidad es *¿Pueden las máquinas pensar?*. Pero, esta pregunta fue desestimada porque prioriza el significado de la palabra *pensar* sobre el tema tratado. Por esto Alan Turing sugirió en vez de realizar dicha pregunta, cuestionar si las máquinas podrían pasar un examen de inteligencia conductual, el **Test de Turing**. 

Este test indica que la máquina debe tener una conversación escrita con un examinador durante cinco minutos y después dicho examinador debe decidir si con quien estaba hablando era humano o no. La máquina pasa el test si engaña a los examinadores un 30% de las veces. Existen dos conclusiones del test a lo largo de la historia: Uno, que ningún examinador preparado fue engañado hasta ahora y Dos, mucha gente ha caído en la trampa si no sabían que el test estaba sucediendo.

A lo largo del tiempo múltiples objeciones surgieron en contra de la posibilidad de maquinas inteligentes, entre ellas las siguientes:
#### El argumento de la discapacidad
Este argumento dice que hay X cosas que una máquina nunca podrá hacer. Este argumento carece de peso pues con el tiempo han aparecido multitudes de programas y máquinas que cumplen tareas específicas, algunas magnitudes a veces mejor que un humano, incluyendo tareas que se creía que se necesitaba conocimiento y entendimiento humano. Esto no significa que la máquina utilice dicho conocimiento y entendimiento, pues no son parte de su comportamiento. El punto hecho en la refutación del argumento es que los procesos necesarios para producir dicho comportamientos suelen ser erróneos o desconocidos por lo que no se puede afirmar que jamás se podrá hacer X o Y cosa.

#### La objeción matemática
Se conoce que existen algunas preguntas matemáticas que en principio no tienen respuesta para lenguajes formales particulares, siendo el teorema de la incompletitud el más famoso de estos. Según el argumento, estas preguntas demostrarían que las máquinas son inferiores mentalmente a las máquinas, pues están limitadas por sus lenguajes formales. Esto ha sido debatido por múltiples frentes entre los cuales surgen los siguientes tres problemas:

Uno: El teorema de incompletitud solo aplica a lenguajes formales lo suficientemente poderosos, refiriéndose a las máquinas teóricas en vez de las reales. Por ejemplo, una máquina de Turing es infinita pero ninguna computadora lo es, entonces si bien se aproximan a dicha máquina de Turing no lo son realmente, por lo que el teorema de incompletitud no aplica realmente.

Dos: Porque cierto agente es incapaz de resolver algo que otros sí no descarta la posibilidad de inteligencia del agente. Por ejemplo, ningún humano podría realizar sumas de millones de números en un tiempo razonable, pero una computadora los realizaría en segundos. No por eso se cuestiona la capacidad de pensamiento de los humanos.

Tres: Incluso si las máquinas poseen limitaciones en su capacidad de resolución, no significa que los humanos no posean sus propias limitaciones. No se conoce como piensa cada persona realmente, por lo que no se puede decir con seguridad que el teorema de incompletitud no nos afecta a nosotros también.

#### El argumento desde la informalidad
Este argumento indica que existe un problema de cualificación en el que no se puede abarcar todo en un conjunto de reglas lógicas, por lo que no hay máquina que pueda realizar comportamientos tan complejos como los humanos. Este argumento ha tenido mucha ida y vuelta en refutaciones y replanteamientos a lo largo que las ciencias de la computación avanzaron pero en resumen se puede afirmar que actualmente existen múltiples formas de acercarse a los problemas a resolver que no requieren de la comprensión inicial total del problema.

### IA Fuerte
Muchos filósofos claman que máquinas que pasen el Test de Turing igualmente no estarían pensando, solo imitando el pensamiento. Para que realmente piensen deberían tener **Conciencia** indican. En esto existen dos posiciones principales, la práctica que simplemente dice *¿Importa? Mientras realice lo que deba hacer que piense si lo desea* y la teórica, que posee mayor disertación en el tema.

Todavía no ha habido una prueba real de que una máquina piense, por lo que la duda continuará hasta que sea demostrado. La respuesta de Turing es llamada la **Convención Cortes** la cual indica que todo ente que actúe tan inteligente como un humano es tan inteligente como un humano, por lo que cuando una máquina alcance ese estado el problema se resolverá. Existe un contrapunto real a esta afirmación que dice: *Los humanos tenemos mentes de verdad, pero las máquinas puede que tengan o no*. Pero este contrapunto trae el problema de la mente y su relación o no al cuerpo humano a la mesa. Para poder confirmar si una máquina podría pensar entonces primero habría que resolver la cuestión de si la mente está inherentemente enlazada al cuerpo orgánico en la que habita.

Existen dos posiciones, una posición **dualista** que asegura que están separados y la mente controla el cuerpo sin ser dependiente de él, pero no hay forma de comprobar esto. En la otra posición, la **monista** o **fisicalista** dice que la mente es parte del cuerpo, que los estados mentales son estados físicos. En la actual sociedad positivista es la dominante y más explorada. Igualmente, trae el problema de **cómo** un estado físico es a la vez un estado mental.

Los siguientes tres experimentos mentales muestran las incongruencias que surgen en la exploración de la IA fuerte

#### El cerebro en la tina
Los fisicalistas explican el problema presentado enfocándose en un tipo particular de estados mentales, estos llamados **estados intencionales**. Estos estados son aquellos relacionados con algún aspecto del mundo exterior. Si el fisicalismo fuera cierto, entonces los estados mentales están determinados por los estados del cerebro, es decir que un estado cerebral no puede corresponder a distintos estados mentales.
Este es un argumento simplista y cae en pedazos con el siguiente experimento mental:

Imagínese que se pudiera extraer el cerebro y colocarlo en una tina especialmente preparada. La tina mantiene vivo al cerebro y lo deja crecer y desarrollarse. Si se conectara una máquina al cerebro que alimentara al mismo con información correspondiente a una simulación, esta simulación podría ser potencialmente idéntica a la vida que el cerebro previamente tuvo cuando estaba en el cuerpo humano. Es decir que una serie de impulsos eléctricos de la computadora está reemplazando los estados mentales para ciertos estados cerebrales.

El contraargumento generado hacia el experimento es indicar que los estados mentales pueden ser interpretados desde dos puntos de vista, uno general y tercerizado, y otro estrecho y personal. Para las IA este segundo es principalmente representativo pues indica cómo suelen funcionar.

#### Experimento de reemplazo cerebral
A partir del problema causado por el problema anterior, una nueva teoría surge, la teoría **funcionalista** que describe los estados mentales como condiciones causales entre entrada y salida. De esta forma dos procesos isomorfos podrían tener el mismo estado mental. Aún sin definir que serían procesos isomorfos se asume que tienen un nivel de abstracción donde la implementación no importa.
Para defender esta teoría se imaginó el siguiente experimento mental: Imagina que una sociedad avanzó lo suficiente para dominar completamente las neurociencias y son capaces de replicar neuronas con nanomáquinas a la perfección y estas son virtualmente indistinguibles a las neuronas. Entonces, suponiendo que uno pudiera trasplantar dichas nanomáquinas reemplazando las neuronas, el experimento sugiere que no debería haber ningún cambio dentro del paciente. Detractores inicialmente indicaron que bien podría haber una pérdida gradual de la consciencia a medida que más parte del cerebro es reemplazada, pero se han realizado múltiples argumentos contra dicha exclamación:

Uno: Para que ocurra dicha pérdida gradual de la consciencia, uno debería perder instantáneamente el control porque sino podría indicar que el cambio ocurre, ergo el experimento falla pues se notan cambios actitudinales.

Dos: ¿Que pasaría si al paciente se le pellizcara? debería responder con una expresión de dolor, escépticos dirían que las máquinas pueden realizar dichas respuestas sin necesitar inteligencia. Pero según el experimento el cerebro artificial es indistinguible al natural por lo que no necesitaría realizar dicha solución. Debe haber una explicación sobre la manifestación de la consciencia producida por el cerebro electrónico se refiere sólo a las partes funcionales de las neuronas. Existen tres conclusiones diferentes:

Uno: Los mecanismos causales de la consciencia que fueron generados por el cerebro todavía funcionan en el artificial, es decir hay consciencia.

Dos: Los eventos mentales conscientes en el cerebro no tienen conexión causal al comportamiento, por lo que el cerebro artificial no los posee, no hay consciencia.

Tres: El experimento es imposible, por lo que la especulación es absurda.

La segunda conclusión no es ignorable pero tampoco es demostrable, pues indica que algo sucede pero no se puede encontrar el donde y como. Se puede decir entonces, que si se acepta que el cerebro puede ser reemplazado y se mantiene la consciencia, entonces esta se debería mantener si se reemplaza con maquinaria que imita perfectamente el funcionamiento del cerebro artificial.

#### La habitación china

En 1980 un desafío al funcionalismo fue montado, el **naturalismo biológico** que indica que los estados mentales son fenómenos emergentes que son causados por procesos físicos en las neuronas. Entonces los estados mentales no podrían ser duplicados simplemente por poseer la misma estructura funcional con el mismo comportamiento entrada-salida, requiriera que el programa funcionara en una arquitectura con el mismo poder causal que las neuronas. Es más, porque una máquina corra correctamente un programa no asegura que entiende que está haciendo, correr el programa no es condición suficiente para tener una mente.

El experimento mental respaldado plantea una habitación con una persona angloparlante, un libro de reglas, una tabla de símbolos extraños, una pila de papel y un lápiz. La habitación recibe papeles con combinaciones de símbolos y la persona sigue las reglas del libro para realizar una respuesta con el lápiz y papel que es retirado de la habitación. La persona no tiene ni idea el contenido de la entrada y salida, pero otra persona reconocería que están en chino y las respuestas son correctas para las preguntas. Es decir, la máquina no entiende lo que está haciendo y aún así produce respuestas satisfactorias.

Este experimento se basa en cuatro axiomas:
Uno: Los programas de computadora son formales (Sintaxis)
Dos: Las mentes humanas tienen contenido mental (Semántica)
Tres: La sintaxis no es por sí misma constitutiva ni suficiente para la semántica
Cuatro: Los cerebros causan mentes
Esto produce una división entre los filósofos, puesto que los primeros dos axiomas dependen de una distinción sin especificar entre semántica y sintaxis. Los primeros tres axiomas existen para refutar el funcionalismo y se ciernen en el tercer axioma, pero aun así aunque sean ciertos, no aseguran si los no cerebros pueden tener mentes. Por eso se produce una división entre los que creen en el naturalismo biológico y el funcionalismo.

Un último problema con el experimento es que supone que la habitación no es una mente basándose en que puede correr el programa, pero no dice nada sobre si podría ser una mente según otra métrica. El experimento depende de la intuición y no pruebas.

### Riesgos Y Ética en el desarrollo de IA
Siempre existen riesgos que surgen del desarrollo de todas las ciencias y la inteligencia artificial posee sus propios problemas relacionados, de los cuales se discutirán algunos a continuación

#### La gente podría perder sus trabajos frente a la automatización
Esto es algo que ha ocurrido con todas las tecnologías que aumentan la eficiencia en el trabajo, puesto a que no necesitas tanta gente para realizar la misma cantidad de resultados. Si se quedara uno solo con esta parte de la discusión entonces sí, se perderían trabajos, pero existe el otro lado de la moneda. Nuevas tecnologías abren camino a nuevas oportunidades laborales que no habrían existido antes. La máquina de coser quitó trabajo a los tejedores pero creó toda la industria de maquinaria, por ejemplo. Las tecnologías remueven la necesidad de participar en trabajos de poco nivel y abren acceso a trabajos de nivel mucho mayor

#### La gente tendría demasiado tiempo libre (o muy poco)
Este es un argumento anticuado pues se basa en teorías económicas que no corresponden a la sociedad de la información moderna. Hoy en día el tiempo es más valioso que nunca, por lo que las jornadas de trabajo tenderán a extenderse demasiado si no existieran agentes informáticos que automatizan una porción significativa del trabajo.

#### La gente perdería la sensación de ser unicos
De la misma forma que ocurrió cuando el heliocentrismo desplazó el geocentrismo, o cuando la teoría de la evolución nos puso al nivel de todos los demás animales. No por eso dejamos de ser lo que somos.

#### Los sistemas IA podrían ser usados para fines indeseables
Todas las ciencias poseen un lado peligroso, de la energía nuclear salió la bomba atómica, de la medicina las armas biológicas y más. En el caso de las IA, poder tener fuerzas armadas con mínimos componentes humanos podría incitar a violencia más descuidada, incitando a su vez a la guerra. Además, retirar al componente humano podría causar que problemas nuevos como ataques a civiles no relacionados, puedan ocurrir. Un último tema que la IA presenta es la pérdida de privacidad en todo ámbito, algo que ya está ocurriendo.

#### El uso de sistemas IA podría resultar en una pérdida de responsabilidad
Este problema sugiere que individuos que fallan en tareas importantes podrían echar la culpa a los fallos de una IA, pero hasta que no aparezcan IA consciente que realicen dichos fallos a propósito, el argumento es algo absurdo. Hoy en día las IA son tratadas como herramientas y sería el equivalente a justificar tu error porque el destornillador se rompió o la calculadora se quedó sin batería. Es la responsabilidad del operario el corroborar que la información que da la IA es correcta y no creer ciegamente en ella.

#### El éxito de la IA podría significar el fin de la humanidad
Este es el problema presentado más viejo e importante pues ha tenido muchas iteraciones a lo largo de la historia, desde frankenstein hasta terminator. Se puede dividir este problema en tres menores:

Uno: La estimación de la IA puede estar errónea y llevarla a realizar la cosa incorrecta. El tema con este riesgo es que no es inherente a las YA si no también a las personas. De la misma forma que un misil con un problema en su navegación puede resultar atacando a una población inocente, puede haber ocurrido por un descuido humano. La solución es realizar un sistema progresivo de chequeos para que nunca una sola lectura errónea se propague a lo largo de todo un sistema

Dos: Especificar la función de utilidad correcta para que la IA maximice no es fácil. Se debe tener cuidado con lo que se pide pues las máquinas no poseen la capacidad de entender el contexto y toman todo lo literalmente presentado. Por esto, se debe continuar avanzando las técnicas de IA para ser capaz de alcanzar ese contexto. Se esperaría que para cuando una IA tuviera la capacidad de destruir la humanidad, sea lo suficientemente inteligente para reconocer que esa no es la solución correcta.

Tres: La función de aprendizaje de una IA podría evolucionar a un sistema con comportamiento inesperado. En su caso más extremo podemos referirnos a la **singularidad tecnológica** donde las IA son capaces de crear IAs mejores y la humanidad o será integrada a la máquina o desaparece. Esto se basa en el crecimiento exponencial que ha tenido la tecnología en las últimas décadas pero no tiene en cuenta el hecho de que todas las demás tecnologías suelen llegar a una meseta eventualmente de la que algunas nunca salen. Con solo un siglo de avances tecnológicos no se podría realizar extrapolaciones confiables de lo que pasará en siglos venideros. 
Existe otro argumento que indica que estas super inteligencias son reduccionistas pues se centran en un solo atributo importante, la inteligencia y que con suficiente de ella todo podría ser resuelto. Pero se sabe que hay límites a la computabilidad y complejidad computacional. Y aun así existen límites físicos de cuánto podría una computadora procesar, por ejemplo, la velocidad de la luz.
Si bien existe gente que teme esta singularidad, existe otra que la anhela, los **transhumanistas** que anticipan el futuro donde la humanidad pueda trascender las limitaciones físicas mediante la intervención de la robótica. Esto se encuentra en directa oposición con la mayoría de teóricos moralistas y éticos modernos, que toman la preservación de la humanidad y la vida humana como un objetivo importante. 

Existen muchas propuestas para poder manejar la situación en caso de que la singularidad pudiera ocurrir, pero todas son altamente teóricas pues estamos hablando de eventos que rayan la ciencia ficción tanto que no se pueden dar información factualmente relevante.

## Opinion Personal
Para ser completamente sinceros, esta discusion me parece una perdida de tiempo. Por el futuro esperable, las maquinas no estan ni de cerca en un estado donde los temas tratados sean relevantes. La mayoria de los experimentos que se presentan requieren de extremos tales como completo entendimiento de las neurociencias, nanotecnologia y demas materias que hoy dia pertenecen a la ciencia ficcion. Aun no se tiene idea que es realmente la vida, o que es realmente el pensamiento. Se sabe que se hospeda en la mente y que el estado de esta lo afecta pero poco mas. En mi creencia personal, el cerebro es el receptaculo del alma y su salud determina que tan bien puede esta reconocer lo que sucede a su alrededor. Las IA no podran pensar realmente mientras sean capaces de hospedar un alma, y cuando puedan, si pueden, es porque el señor decidio permitirnos crear entes a nuestra semejanza como nosotros somos de El. No siento la necesidad de profundizar mas en este debate pues esta en manos de Dios si sucede y cuando lo haga.

# Ejercicio 3
La señora Bender en el articulo **You are not a Parrot** se demuestra peleando una batalla contra la naturaleza humana. Es propio de nuestra especie el reconocer patrones y asociarlos con caracteristicas humanas, dicho fenomeno recibe el nombre de Pareidolia. Este fenomeno es un efecto secundario de nuestra capacidad de percepcion, clave en nuestro desarrollo evolutivo y, es posiblemente el origen de muchos de nuestras costumbres, comportamientos y tradiciones a lo largo de toda la historia.
De la misma forma que la Pareidolia produce efectos inocuos como reconocer figuras en las nubes o caras en las grietas de una pared, esta misma es el origen de cosas como la empatia a seres no humanos, al reconocer en cualquier animal pequeño, con cabeza redonda u ojos grandes cualidades asociadas con bebes o infantes, es decir seres que deben ser protegidos o cuidados. Siguiendo con este ejemplo, si no poseyeramos esta particularidad, aun reconociendo un cachorro, este seria asociado solo con una fuente de comida facil, en vez de lo mencionado previamente.
Existen muchos ejemplos de coexistencia y relaciones simbioticas en la naturaleza, pero casos claros de un ente cuidando de otros por motivos no utilitarios son sorprendentemente pocos. Es mas, animales que se han encontrado cuidando de crias de otras especies tienden a ser hembras que perdieron las propias y se consideran con demencia.

Asi como el ejemplo dado existen muchos, el concepto de destino y las religiones primitivas son esencialmente reconocer intencionalidad en eventos que pueden haber sido aleatorios, una temporada de lluvia justo cuando un cultivo mas lo necesitaba por ejemplo.
El punto que quiero indicar es que los problemas que esta persona indica no son mas que la Pareidolia en accion, una recreacion de estos eventos en la actualidad. Bajo el argumento que ella presenta no deberiamos haber nunca cuidado del cachorro, pues no es ser humano, no deberiamos sentir jolgorio porque Zeus bendijo la cosecha, debido a que fue casualidad; solo debemos sentir y asociar cualidades humanas al ser humano.

"¡No debes empatizar con la maquina! ¡No entiende lo que dices!" ella exclama, pero de la misma forma un perro no entiende que *buen chico* significa, ni la lluvia sabe que tus plantas la necesitaban. La maquina no necesita ser consciente para que lo que diga tenga valor, especialmente para seres tan emocionales como el ser humano. Un "¡tu puedes!" es igual de efectivo para quien realmente lo necesita sea el que lo diga un extraño, una maquina o quien sea.
Esta guerra que Bender esta lidiando es en esencia nadar contracorriente con lo que nos hace humanos, lo que nos diferencia de otros animales y la llevo hasta el extremo de no querer debatir ideas con gente que no coincida al menos parcialmente con ella.
